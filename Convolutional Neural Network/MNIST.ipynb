{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set, Validation set, Test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Để đánh giá xem model có học không hay chỉ nhớ cũng như khi dùng ngoài thực tế thì performance sẽ thế nào, người ta chia dataset làm 3 tập traning set, validation set và test set. \n",
    "- Mình sẽ cho model học trên tập training set và đánh giá model trên tập validation set. \n",
    "- Nếu có nhiều hơn 1 mô hình (ví dụ VGG16, VGG19,...) thì mô hình nào cho performance tốt hơn trên\n",
    "tập validation set sẽ được chọn. Và cuối cùng model tốt nhất sẽ được đánh giá trên tập test set làm\n",
    "hiệu suất của model khi dùng thực tế. \n",
    "- Nhận thấy là tập test set không được dùng trong cả quá trình\n",
    "training chỉ đến cuối dùng để đánh giá.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nhắc lại bài neural network, ở mỗi layer sẽ thực hiện 2 bước: tính tổng linear các node ở layer trước\n",
    "và thực hiện activation function (ví dụ sigmoid function, softmax function). Do sau bước tính tổng\n",
    "linear cho ra các giá trị thực nên cần dùng softmax function dùng để chuyển đổi giá trị thực trong\n",
    "các node ở output layer sang giá trị phần trăm.\n",
    "- Vì mỗi ảnh sẽ thuộc 1 class từ 0 đến 9, nên tất cả sẽ có 10 class. Nên output layer sẽ có 10\n",
    "node để tương ứng với phần trăm ảnh là số 0,1,..,9. Ví dụ: a6 là xác suất ảnh là số 5.\n",
    "> Với các bài toán classification (phân loại) thì nếu có 2 lớp thì hàm activation ở output layer\n",
    "là hàm sigmoid và hàm loss function là binary_crossentropy, còn nhiều hơn 2 lớp thì hàm\n",
    "activation ở ouput layer là hàm softmax với loss function là hàm categorical_crossentropy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(p,q) = -\\sum_{x}p(x)logq(x)$$\n",
    "\n",
    "> p is the true probability distribution and q is the predicted probability distribution\n",
    "\n",
    "$$L =-\\sum_{i=1}^{10}y_i*log(\\hat{y}_i)$$\n",
    "\n",
    "\n",
    "=> Hàm L nhỏ khi giá trị model dự đoán gần với giá trị thật và rất lớn khi model dự đoán sai, hay\n",
    "nói cách khác L càng nhỏ thì model dự đoán càng gần với giá trị thật. => Bài toán tìm model trở\n",
    "thành tìm giá trị nhỏ nhất của L.\n",
    ">Hàm loss function định nghĩa như trên trong keras gọi là \"categorical_crossentropy\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Thêm các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dữ liệu MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_val, y_val = X_train[50000:60000,:], y_train[50000:60000]\n",
    "X_train, y_train = X_train[:50000,:], y_train[:50000]\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reshape lại dữ liệu cho đúng kích thước mà keras yêu cầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. One hot encoding label (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu y ban đầu  5\n",
      "Dữ liệu y sau one-hot encoding  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_val = np_utils.to_categorical(y_val, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "print('Dữ liệu y ban đầu ', y_train[0])\n",
    "print('Dữ liệu y sau one-hot encoding ',Y_train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Định nghĩa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Thêm Convolutional layer với 32 kernel, kích thước kernel 3*3\n",
    "# dùng hàm sigmoid làm activation và chỉ rõ input_shape cho layer đầu tiên\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "# Thêm Convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n",
    "# Thêm Max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Flatten layer chuyển từ tensor sang vector\n",
    "model.add(Flatten())\n",
    "# Thêm Fully Connected layer với 128 nodes và dùng hàm sigmoid\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "# Output layer với 10 node và dùng softmax function để chuyển sang xác suất.\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile model, chỉ rõ hàm loss_function nào được sử dụng, phương thức đùng để tối ưu hàm loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Thực hiện train model với data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.2518 - accuracy: 0.9272 - val_loss: 0.0677 - val_accuracy: 0.9815\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.0534 - accuracy: 0.9851 - val_loss: 0.0500 - val_accuracy: 0.9851\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.0334 - accuracy: 0.9904 - val_loss: 0.0424 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0441 - val_accuracy: 0.9871\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0394 - val_accuracy: 0.9873\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0370 - val_accuracy: 0.9895\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0404 - val_accuracy: 0.9893\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0421 - val_accuracy: 0.9881\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0386 - val_accuracy: 0.9899\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0466 - val_accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n",
    "            batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Vẽ đồ thị loss, accuracy của training set và validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m      2\u001b[0m numOfEpoch \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, numOfEpoch), H\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "numOfEpoch = 10\n",
    "plt.plot(np.arange(0, numOfEpoch), H.history['loss'], label='training loss')\n",
    "plt.plot(np.arange(0, numOfEpoch), H.history['val_loss'], label='validation loss')\n",
    "plt.plot(np.arange(0, numOfEpoch), H.history['acc'], label='accuracy')\n",
    "plt.plot(np.arange(0, numOfEpoch), H.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy and Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss|Accuracy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Đánh giá model với dữ liệu test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Dự đoán ảnh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[0].reshape(28,28), cmap='gray')\n",
    "y_predict = model.predict(X_test[0].reshape(1,28,28,1))\n",
    "print('Giá trị dự đoán: ', np.argmax(y_predict))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
